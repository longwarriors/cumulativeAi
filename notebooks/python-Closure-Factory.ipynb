{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 工厂函数（Factory Function）\n",
    "- 外层函数（工厂函数）定义了一些变量。\n",
    "- 内层函数（返回的函数）捕获这些变量的引用。\n",
    "- 返回的内层函数形成闭包，保留对外层函数变量的访问能力。\n",
    "- 如果内层函数需要修改外层函数的变量，必须使用 **nonlocal** 声明，否则 Python 会认为是在创建局部变量。\n",
    "- 虽然工厂函数通常利用闭包机制，但并非所有工厂函数都是闭包。如果工厂函数返回的内层函数不依赖外层函数的变量（即没有捕获自由变量），则不构成闭包。"
   ],
   "id": "82d7a3ee2effb146"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-15T06:37:09.475031Z",
     "start_time": "2025-08-15T06:37:09.471817Z"
    }
   },
   "source": [
    "def make_adder(x):\n",
    "    def adder(y):\n",
    "        return x + y\n",
    "\n",
    "    return adder\n",
    "\n",
    "\n",
    "adder100 = make_adder(100)\n",
    "adder200 = make_adder(200)\n",
    "print(adder100(10))  # 输出: 110\n",
    "print(adder200(10))  # 输出: 210"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "210\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T06:56:37.780899Z",
     "start_time": "2025-08-15T06:56:37.776451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_counter():\n",
    "    count = 0\n",
    "\n",
    "    def counter():\n",
    "        nonlocal count  # 使用 nonlocal 关键字来修改外层函数的变量\n",
    "        count += 1\n",
    "        return count\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "counter1 = make_counter()\n",
    "counter2 = make_counter()\n",
    "\n",
    "counter1()\n",
    "counter1()\n",
    "counter1()\n",
    "\n",
    "counter2()\n",
    "counter2()\n",
    "counter2()\n",
    "counter2()\n",
    "\n",
    "print(counter1())\n",
    "print(counter2())"
   ],
   "id": "4765e68d0e13bf56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T07:52:56.882871Z",
     "start_time": "2025-08-15T07:52:56.878568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 外层变量的修改会影响闭包的行为\n",
    "def make_funcs():\n",
    "    funcs = []\n",
    "    for i in range(3):\n",
    "        def func():\n",
    "            return i  # 注意这里的 i 是外层变量\n",
    "\n",
    "        funcs.append(func)\n",
    "    return funcs\n",
    "\n",
    "\n",
    "three_funcs = make_funcs()\n",
    "print(three_funcs[0]())  # 输出: 2\n",
    "print(three_funcs[1]())  # 输出: 2\n",
    "print(three_funcs[2]())  # 输出: 2"
   ],
   "id": "c04caa3d3686a123",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T08:03:14.039382Z",
     "start_time": "2025-08-15T08:03:14.034913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_funcs_fixed():\n",
    "    funcs = []\n",
    "    for i in range(3):\n",
    "        def func(x=i):  # 使用默认参数来捕获当前的 i 值\n",
    "            return x\n",
    "\n",
    "        funcs.append(func)\n",
    "    return funcs\n",
    "\n",
    "\n",
    "three_funcs_fixed = make_funcs_fixed()\n",
    "print(three_funcs_fixed[0]())  # 输出: 0\n",
    "print(three_funcs_fixed[1]())  # 输出: 1\n",
    "print(three_funcs_fixed[2]())  # 输出: 2"
   ],
   "id": "f5cf0ecf60601af4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 闭包（Closure）\n",
    "函数在定义时就确定了其作用域，而不是在调用时。\n",
    "- 在异步编程中，闭包常用于回调函数以保留上下文。\n",
    "- 函数工厂，动态生成具有特定行为的函数。\n",
    "- 变量封装，闭包可以隐藏变量，防止外部直接访问，从而实现数据私有化。"
   ],
   "id": "7b35266ba0ef0c38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T08:40:07.339753Z",
     "start_time": "2025-08-15T08:40:06.474572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义学习率调度器\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "def make_lr_scheduler(initial_lr, decay_rate):\n",
    "    def lr_scheduler(step):\n",
    "        lr = initial_lr / (1 + decay_rate * step)\n",
    "        return lr\n",
    "\n",
    "    return lr_scheduler\n",
    "\n",
    "LR_0 = 1e-3\n",
    "lr_scheduler = make_lr_scheduler(initial_lr=LR_0, decay_rate=0.1)\n",
    "model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 1))\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_0)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    inputs = torch.randn(32, 10)  # 假设输入数据\n",
    "    targets = torch.randn(32, 1)  # 假设目标数据\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 更新学习率\n",
    "    curr_lr = lr_scheduler(epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = curr_lr\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}, Learning Rate: {curr_lr:.4f}')\n"
   ],
   "id": "52e5e11d69aa57cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4223, Learning Rate: 0.0010\n",
      "Epoch 2, Loss: 0.7373, Learning Rate: 0.0009\n",
      "Epoch 3, Loss: 1.1607, Learning Rate: 0.0008\n",
      "Epoch 4, Loss: 0.8987, Learning Rate: 0.0008\n",
      "Epoch 5, Loss: 0.9922, Learning Rate: 0.0007\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:01:20.843308Z",
     "start_time": "2025-08-15T09:01:20.757704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义优化器\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "def make_loss_closure(model, criterion, inputs, targets):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    return closure\n",
    "\n",
    "model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 1))\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.1) # LBFGS 优化器需要闭包\n",
    "criterion = nn.MSELoss()\n",
    "inputs = torch.randn(32, 10)  # 假设输入数据\n",
    "targets = torch.randn(32, 1)  # 假设目标数据\n",
    "loss_closure = make_loss_closure(model, criterion, inputs, targets)\n",
    "for epoch in range(5):\n",
    "    optimizer.step(loss_closure)  # 调用闭包计算损失并更新参数\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss_closure().item():.6f}')"
   ],
   "id": "f99ff9a1a3aa5148",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.166608\n",
      "Epoch 2, Loss: 0.006464\n",
      "Epoch 3, Loss: 0.000283\n",
      "Epoch 4, Loss: 0.000006\n",
      "Epoch 5, Loss: 0.000000\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:19:23.346255Z",
     "start_time": "2025-08-15T09:19:23.330203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 回调函数\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "def make_train_callback():\n",
    "    metrics = {\"losses\": [], \"epoch\": 0}\n",
    "    def callback(model, loss):\n",
    "        metrics[\"losses\"].append(loss.item())\n",
    "        metrics[\"epoch\"] += 1\n",
    "        print(f'Epoch {metrics[\"epoch\"]}, Loss: {loss.item():.4f}')\n",
    "        if metrics['epoch'] % 2 == 0:\n",
    "            torch.save(model.state_dict(), f'model_epoch_{metrics[\"epoch\"]}.pth')\n",
    "    return callback\n",
    "\n",
    "model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 1))\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "callback = make_train_callback()\n",
    "\n",
    "for epoch in range(5):\n",
    "    inputs = torch.randn(32, 10)\n",
    "    targets = torch.randn(32, 1)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    callback(model, loss)  # 调用回调函数"
   ],
   "id": "11b5d60a2c8a7fe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8360\n",
      "Epoch 2, Loss: 0.8866\n",
      "Epoch 3, Loss: 1.0002\n",
      "Epoch 4, Loss: 1.1965\n",
      "Epoch 5, Loss: 1.1751\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "592e5d40ef993342"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
