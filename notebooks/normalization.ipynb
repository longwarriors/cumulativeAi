{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-17T03:22:46.532452Z",
     "start_time": "2025-07-17T03:22:46.525039Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([\n",
    "    [\n",
    "        [0.1, 0.2, 0.3, 0.4],  # 句子 1, 词 1\n",
    "        [0.5, 0.6, 0.7, 0.8],  # 句子 1, 词 2\n",
    "        [0.9, 1.0, 1.1, 1.2]   # 句子 1, 词 3\n",
    "    ],\n",
    "    [\n",
    "        [10.0, 11.0, 12.0, 13.0], # 句子 2, 词 1\n",
    "        [14.0, 15.0, 16.0, 17.0], # 句子 2, 词 2\n",
    "        [18.0, 19.0, 20.0, 21.0]  # 句子 2, 词 3\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "B, T, C = X.shape\n",
    "\n",
    "layernorm = nn.LayerNorm(N)  # N 是特征维度\n",
    "X_ln = layernorm(X)\n",
    "print(\"LayerNorm 后的输出:\\n\", X_ln)\n",
    "print(f\"LayerNorm 后的均值:\\n{X_ln.mean(dim=-1)}， 方差:\\n{X_ln.var(dim=-1, unbiased=False)}\")\n",
    "\n",
    "sentence1_wordvec1 = X[0, 0, :]  # 句子 1 的词 1 的向量\n",
    "vec_mean = sentence1_wordvec1.mean(0)\n",
    "vec_var = sentence1_wordvec1.var(unbiased=False)  # LayerNorm默认使用有偏估计\n",
    "epsilon = 1e-5  # 防止除零\n",
    "vec_norm = (sentence1_wordvec1 - vec_mean) / (vec_var + epsilon).sqrt()\n",
    "print(f\"\\n句子 1 的词 1 的向量:\\n{sentence1_wordvec1}\")\n",
    "print(f\"均值: {vec_mean}, 方差: {vec_var}, 归一化向量: {vec_norm}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayerNorm 后的输出:\n",
      " tensor([[[-1.3411, -0.4470,  0.4470,  1.3411],\n",
      "         [-1.3411, -0.4470,  0.4470,  1.3411],\n",
      "         [-1.3411, -0.4470,  0.4470,  1.3411]],\n",
      "\n",
      "        [[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "LayerNorm 后的均值:\n",
      "tensor([[ 2.9802e-08, -2.9802e-07,  5.3644e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<MeanBackward1>)， 方差:\n",
      "tensor([[0.9992, 0.9992, 0.9992],\n",
      "        [1.0000, 1.0000, 1.0000]], grad_fn=<VarBackward0>)\n",
      "\n",
      "句子 1 的词 1 的向量:\n",
      "tensor([0.1000, 0.2000, 0.3000, 0.4000])\n",
      "均值: 0.25, 方差: 0.012500000186264515, 归一化向量: tensor([-1.3411, -0.4470,  0.4470,  1.3411])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:35:22.312091Z",
     "start_time": "2025-07-17T03:35:22.305771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_reshape = X.view(-1, C)\n",
    "print(X_reshape)\n",
    "batchnorm = nn.BatchNorm1d(C)\n",
    "X_bn = batchnorm(X_reshape)\n",
    "print(X_bn)\n",
    "X_bn_fold = X_bn.view(B, T, C)\n",
    "print(\"BatchNorm 后的输出还原张量形状:\\n\", X_bn_fold)"
   ],
   "id": "48a66b5896fdafd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1000,  0.2000,  0.3000,  0.4000],\n",
      "        [ 0.5000,  0.6000,  0.7000,  0.8000],\n",
      "        [ 0.9000,  1.0000,  1.1000,  1.2000],\n",
      "        [10.0000, 11.0000, 12.0000, 13.0000],\n",
      "        [14.0000, 15.0000, 16.0000, 17.0000],\n",
      "        [18.0000, 19.0000, 20.0000, 21.0000]])\n",
      "tensor([[-1.0017, -1.0046, -1.0070, -1.0088],\n",
      "        [-0.9457, -0.9518, -0.9569, -0.9613],\n",
      "        [-0.8896, -0.8989, -0.9069, -0.9138],\n",
      "        [ 0.3853,  0.4230,  0.4566,  0.4866],\n",
      "        [ 0.9457,  0.9518,  0.9569,  0.9613],\n",
      "        [ 1.5061,  1.4805,  1.4573,  1.4360]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "BatchNorm 后的输出还原张量形状:\n",
      " tensor([[[-1.0017, -1.0046, -1.0070, -1.0088],\n",
      "         [-0.9457, -0.9518, -0.9569, -0.9613],\n",
      "         [-0.8896, -0.8989, -0.9069, -0.9138]],\n",
      "\n",
      "        [[ 0.3853,  0.4230,  0.4566,  0.4866],\n",
      "         [ 0.9457,  0.9518,  0.9569,  0.9613],\n",
      "         [ 1.5061,  1.4805,  1.4573,  1.4360]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:39:50.044583Z",
     "start_time": "2025-07-17T03:39:50.040070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature1 = X_reshape[:, 0]  # 取第一个样本的特征向量\n",
    "feature1_mean = feature1.mean()\n",
    "feature1_var = feature1.var(unbiased=False)  # 使用有偏估计\n",
    "epsilon = 1e-5  # 防止除零\n",
    "feature1_norm = (feature1 - feature1_mean) / (feature1_var + epsilon).sqrt()\n",
    "print(f\"\\n第一个特征的归一化:\\n{feature1_norm}\")"
   ],
   "id": "536258d5624d2934",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第一个特征的归一化:\n",
      "tensor([-1.0017, -0.9457, -0.8896,  0.3853,  0.9457,  1.5061])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "402eee0825718ec2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
