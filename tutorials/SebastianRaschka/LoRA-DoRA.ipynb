{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:04:49.232789Z",
     "start_time": "2025-07-04T07:04:44.260281Z"
    }
   },
   "source": [
    "# https://github.com/rasbt/dora-from-scratch\n",
    "# https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch\n",
    "\n",
    "from utils import EarlyStopping, train_loop_with_resume\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.backends.cudnn.deterministic = True"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T07:04:52.779524Z",
     "start_time": "2025-07-04T07:04:52.728272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###########################\n",
    "#### Settings\n",
    "###########################\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "###########################\n",
    "#### mnist dataset\n",
    "###########################\n",
    "labelled_set = datasets.MNIST(root='../../data', train=True, transform=transforms.ToTensor(), download=False)\n",
    "test_set = datasets.MNIST(root='../../data', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(TRAIN_RATIO * len(labelled_set))\n",
    "valid_size = len(labelled_set) - train_size\n",
    "train_set, valid_set = random_split(labelled_set, [train_size, valid_size])\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 检查数据集张量维度\n",
    "check_batch = next(iter(train_loader))\n",
    "print(f\"批次数据维度: {check_batch[0].shape}, 标签维度: {check_batch[1].shape}\")"
   ],
   "id": "cdb9adebac9fa70f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次数据维度: torch.Size([128, 1, 28, 28]), 标签维度: torch.Size([128])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T07:06:06.579297Z",
     "start_time": "2025-07-04T07:05:47.519892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#############################\n",
    "#### Hyperparameters\n",
    "#############################\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "LEARNING_RATE = 5e-3\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "#############################\n",
    "#### Architecture\n",
    "#############################\n",
    "n_features = 28 * 28  # MNIST images are 28x28 pixels\n",
    "n_classes = 10\n",
    "n_hidden1 = 256\n",
    "n_hidden2 = 64\n",
    "\n",
    "\n",
    "#############################\n",
    "#### Perceptron Model\n",
    "#############################\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, in_features, hidden1, hidden2, out_features, rank=4, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # 展平输入\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_pretrained = MultiLayerPerceptron(n_features, n_hidden1, n_hidden2, n_classes).to(DEVICE)\n",
    "optimizer_pretrained = optim.Adam(model_pretrained.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(optimizer_pretrained, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
    "early_stopping = EarlyStopping(patience=3, delta=1e-4, mode=\"max\")\n",
    "best_ckpt_file_path = \"best_pretrained.pth\"\n",
    "# 训练\n",
    "accuracy, discord = train_loop_with_resume(\n",
    "    model_pretrained,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    criterion,\n",
    "    optimizer_pretrained,\n",
    "    scheduler,\n",
    "    early_stopping,\n",
    "    best_ckpt_file_path,\n",
    "    NUM_EPOCHS,\n",
    "    DEVICE,\n",
    ")\n",
    "print(f\"训练过程损失: {discord['train_loss']}\")\n",
    "print(f\"训练过程准确率: {discord['train_acc']}\")\n",
    "print(f\"验证过程损失: {discord['valid_loss']}\")\n",
    "print(f\"验证过程准确率: {discord['valid_acc']}\")"
   ],
   "id": "46fa15aed37fcae1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from best_pretrained.pth, resume from epoch 14\n",
      "加载训练点模型成功，当前准确率为0.9958，从第14个epoch开始训练...\n",
      "\n",
      "Epoch 15/50 - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前验证准确率: 0.9959\n",
      "当前学习率: 1.00e-06\n",
      "更新最佳验证准确率: 0.9959\n",
      "Checkpoint saved to best_pretrained.pth\n",
      "\n",
      "Epoch 16/50 - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前验证准确率: 0.9959\n",
      "当前学习率: 5.56e-05\n",
      "\n",
      "Epoch 17/50 - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前验证准确率: 0.9960\n",
      "当前学习率: 2.17e-04\n",
      "更新最佳验证准确率: 0.9960\n",
      "Checkpoint saved to best_pretrained.pth\n",
      "\n",
      "Epoch 18/50 - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前验证准确率: 0.9957\n",
      "早停触发!\n",
      "训练过程损失: [0.0085473161439877, 0.007274437322029067, 0.0074007072673897105, 0.007215604644453076]\n",
      "训练过程准确率: [0.998125, 0.9983125, 0.9982708333333333, 0.9984791666666667]\n",
      "验证过程损失: [0.018689847316398906, 0.018686501401321342, 0.0184339152694835, 0.018809774229303]\n",
      "验证过程准确率: [0.9959166666666667, 0.9959166666666667, 0.996, 0.9956666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T16:24:41.070506Z",
     "start_time": "2025-07-03T16:24:41.062033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank, alpha):\n",
    "        super().__init__()\n",
    "        std_dev = torch.tensor(1 / rank).sqrt()\n",
    "        self.A = nn.Parameter(torch.randn(in_features, rank) * std_dev)\n",
    "        self.B = nn.Parameter(torch.zeros(rank, out_features))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearWithLoRA(nn.Module):\n",
    "    \"\"\"带LoRA的线性层\"\"\"\n",
    "\n",
    "    def __init__(self, linear_layer: nn.Linear, rank: int = 4, alpha: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.linear = linear_layer\n",
    "        for param in self.linear.parameters():\n",
    "            param.requires_grad = False  # 冻结原线性层的参数\n",
    "        self.lora = LoRALayer(linear_layer.in_features, linear_layer.out_features, rank, alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 不考虑计算效率\n",
    "        # return self.linear(x) + self.lora(x)\n",
    "        # 计算合并后的权重矩阵: W_original + alpha * (A @ B)^T\n",
    "        # 注意：linear层的权重矩阵形状是(out_features, in_features)，所以需要转置\n",
    "        W_lora = self.lora.alpha * (self.lora.A @ self.lora.B).T\n",
    "        W_linear = self.linear.weight\n",
    "        W_combined = W_lora + W_linear\n",
    "        return F.linear(x, W_combined, self.linear.bias)\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "model_lora = copy.deepcopy(model_pretrained)\n",
    "# 替换模型中的线性层为带LoRA的线性层\n",
    "model_lora.fc1 = LinearWithLoRA(model_lora.fc1, rank=4, alpha=1.0)\n",
    "model_lora.fc2 = LinearWithLoRA(model_lora.fc2, rank=4, alpha=1.0)\n",
    "model_lora.fc3 = LinearWithLoRA(model_lora.fc3, rank=4, alpha=1.0)\n",
    "model_lora"
   ],
   "id": "ccd32688cb07a13c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerPerceptron(\n",
       "  (fc1): LinearWithLoRA(\n",
       "    (linear): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (lora): LoRALayer()\n",
       "  )\n",
       "  (fc2): LinearWithLoRA(\n",
       "    (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (lora): LoRALayer()\n",
       "  )\n",
       "  (fc3): LinearWithLoRA(\n",
       "    (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (lora): LoRALayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_lora_parameters(model, filename=\"lora_parameters.pth\"):\n",
    "    \"\"\"保存LoRA参数\"\"\"\n",
    "    lora_params = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LoRALayer):\n",
    "            lora_params[name + \".A\"] = module.A\n",
    "            lora_params[name + \".B\"] = module.B\n",
    "            lora_params[name + \".alpha\"] = module.alpha\n",
    "    torch.save(lora_params, filename)\n",
    "    print(f\"LoRA参数已保存到 {filename}\")"
   ],
   "id": "1b33191190d10863"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T15:43:24.151676Z",
     "start_time": "2025-07-03T15:41:37.341712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "optimizer_lora = optim.Adam(model_lora.parameters(), lr=LEARNING_RATE)\n",
    "print(\"开始训练带LoRA的模型...\")\n",
    "model_lora.to(DEVICE)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model_lora, train_loader, optimizer_lora, criterion, DEVICE\n",
    "    )\n",
    "    valid_loss, valid_acc = validate_epoch(model_lora, valid_loader, criterion, DEVICE)\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        torch.save(model_lora.state_dict(), \"best_model_lora.pth\")\n",
    "        print(f\"最佳验证准确率: {best_acc:.4f}，模型已保存\")"
   ],
   "id": "71e3f70a7fb67a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练带LoRA的模型...\n",
      "\n",
      "Epoch 1/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳验证准确率: 0.9769，模型已保存\n",
      "\n",
      "Epoch 2/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳验证准确率: 0.9774，模型已保存\n",
      "\n",
      "Epoch 3/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳验证准确率: 0.9782，模型已保存\n",
      "\n",
      "Epoch 4/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳验证准确率: 0.9788，模型已保存\n",
      "\n",
      "Epoch 6/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳验证准确率: 0.9789，模型已保存\n",
      "\n",
      "Epoch 10/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class LinearWithLoRA(nn.Module):\n",
    "    \"\"\"带LoRA的线性层\"\"\"\n",
    "\n",
    "    def __init__(self, linear_layer, rank=4, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.linear = linear_layer\n",
    "        # 冻结原始线性层的参数\n",
    "        for param in self.linear.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # LoRA参数\n",
    "        std_dev = 1.0 / rank ** 0.5\n",
    "        self.lora_A = nn.Parameter(torch.randn(linear_layer.in_features, rank) * std_dev)\n",
    "        self.lora_B = nn.Parameter(torch.zeros(rank, linear_layer.out_features))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算合并后的权重矩阵\n",
    "        lora_weight = self.alpha * (self.lora_A @ self.lora_B).T\n",
    "        combined_weight = self.linear.weight + lora_weight\n",
    "        return F.linear(x, combined_weight, self.linear.bias)\n",
    "\n",
    "\n",
    "class MultiLayerPerceptronWithLoRA(nn.Module):\n",
    "    def __init__(self, in_features, hidden1, hidden2, out_features, rank=4, alpha=1.0):\n",
    "        super().__init__()\n",
    "        # 创建原始线性层\n",
    "        self.fc1 = LinearWithLoRA(nn.Linear(in_features, hidden1), rank, alpha)\n",
    "        self.fc2 = LinearWithLoRA(nn.Linear(hidden1, hidden2), rank, alpha)\n",
    "        self.fc3 = LinearWithLoRA(nn.Linear(hidden2, out_features), rank, alpha)\n",
    "\n",
    "        # 保存超参数以便重建模型\n",
    "        self.config = {\n",
    "            'in_features': in_features,\n",
    "            'hidden1': hidden1,\n",
    "            'hidden2': hidden2,\n",
    "            'out_features': out_features,\n",
    "            'rank': rank,\n",
    "            'alpha': alpha\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # 展平输入\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def save_lora_parameters(self, filepath):\n",
    "        \"\"\"只保存LoRA参数\"\"\"\n",
    "        lora_state_dict = {}\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, LinearWithLoRA):\n",
    "                lora_state_dict[f\"{name}.lora_A\"] = module.lora_A\n",
    "                lora_state_dict[f\"{name}.lora_B\"] = module.lora_B\n",
    "\n",
    "        torch.save({\n",
    "            'lora_state_dict': lora_state_dict,\n",
    "            'config': self.config\n",
    "        }, filepath)\n",
    "        print(f\"LoRA参数已保存到: {filepath}\")\n",
    "\n",
    "    def load_lora_parameters(self, filepath):\n",
    "        \"\"\"加载LoRA参数\"\"\"\n",
    "        checkpoint = torch.load(filepath)\n",
    "        lora_state_dict = checkpoint['lora_state_dict']\n",
    "\n",
    "        for name, param in lora_state_dict.items():\n",
    "            # 解析参数名称\n",
    "            module_name, param_name = name.rsplit('.', 1)\n",
    "            module = dict(self.named_modules())[module_name]\n",
    "            setattr(module, param_name, nn.Parameter(param))\n",
    "\n",
    "        print(f\"LoRA参数已从 {filepath} 加载\")\n",
    "\n",
    "    def get_lora_state_dict(self):\n",
    "        \"\"\"获取LoRA参数的state_dict\"\"\"\n",
    "        lora_state_dict = {}\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, LinearWithLoRA):\n",
    "                lora_state_dict[f\"{name}.lora_A\"] = module.lora_A\n",
    "                lora_state_dict[f\"{name}.lora_B\"] = module.lora_B\n",
    "        return lora_state_dict\n",
    "\n",
    "\n",
    "# 工具函数：从预训练模型创建LoRA模型\n",
    "def create_lora_model_from_pretrained(pretrained_model, rank=4, alpha=1.0):\n",
    "    \"\"\"从预训练的普通MLP创建LoRA版本\"\"\"\n",
    "    # 假设预训练模型有fc1, fc2, fc3\n",
    "    config = {\n",
    "        'in_features': pretrained_model.fc1.in_features,\n",
    "        'hidden1': pretrained_model.fc1.out_features,\n",
    "        'hidden2': pretrained_model.fc2.out_features,\n",
    "        'out_features': pretrained_model.fc3.out_features,\n",
    "        'rank': rank,\n",
    "        'alpha': alpha\n",
    "    }\n",
    "\n",
    "    # 创建LoRA模型\n",
    "    lora_model = MultiLayerPerceptronWithLoRA(**config)\n",
    "\n",
    "    # 复制预训练权重到LoRA模型的linear层\n",
    "    lora_model.fc1.linear.load_state_dict(pretrained_model.fc1.state_dict())\n",
    "    lora_model.fc2.linear.load_state_dict(pretrained_model.fc2.state_dict())\n",
    "    lora_model.fc3.linear.load_state_dict(pretrained_model.fc3.state_dict())\n",
    "\n",
    "    return lora_model\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 创建并训练模型\n",
    "    model = MultiLayerPerceptronWithLoRA(784, 256, 128, 10, rank=4, alpha=1.0)\n",
    "\n",
    "    # 模拟训练数据\n",
    "    x = torch.randn(32, 784)\n",
    "    y = torch.randint(0, 10, (32,))\n",
    "\n",
    "    # 模拟训练过程\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # 2. 保存参数的不同方式\n",
    "\n",
    "    # 方式1: 保存完整模型\n",
    "    torch.save(model.state_dict(), 'full_model.pth')\n",
    "    print(\"完整模型已保存\")\n",
    "\n",
    "    # 方式2: 只保存LoRA参数\n",
    "    model.save_lora_parameters('lora_only.pth')\n",
    "\n",
    "    # 方式3: 分别保存（推荐用于生产环境）\n",
    "    # 保存基础模型（可以多个LoRA适应器共享）\n",
    "    base_state_dict = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LinearWithLoRA):\n",
    "            base_state_dict[f\"{name}.linear.weight\"] = module.linear.weight\n",
    "            base_state_dict[f\"{name}.linear.bias\"] = module.linear.bias\n",
    "\n",
    "    torch.save({\n",
    "        'base_state_dict': base_state_dict,\n",
    "        'config': model.config\n",
    "    }, 'base_model.pth')\n",
    "    print(\"基础模型已保存\")\n",
    "\n",
    "    # 3. 加载参数示例\n",
    "    print(\"\\n=== 加载测试 ===\")\n",
    "\n",
    "    # 创建新模型并加载完整参数\n",
    "    new_model = MultiLayerPerceptronWithLoRA(784, 256, 128, 10, rank=4, alpha=1.0)\n",
    "    new_model.load_state_dict(torch.load('full_model.pth'))\n",
    "    print(\"完整模型加载成功\")\n",
    "\n",
    "    # 验证输出一致性\n",
    "    with torch.no_grad():\n",
    "        original_output = model(x)\n",
    "        loaded_output = new_model(x)\n",
    "        print(f\"输出差异: {torch.max(torch.abs(original_output - loaded_output)).item():.8f}\")\n",
    "\n",
    "    # 4. 显示参数统计\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    lora_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\n参数统计:\")\n",
    "    print(f\"总参数数量: {total_params:,}\")\n",
    "    print(f\"LoRA参数数量: {lora_params:,}\")\n",
    "    print(f\"可训练参数比例: {lora_params / total_params:.2%}\")"
   ],
   "id": "599a9f7ae97c56f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
